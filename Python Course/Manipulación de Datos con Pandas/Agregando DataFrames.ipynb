{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Media y mediana\n",
    "Las estadísticas de resumen son exactamente lo que su nombre implica - resumen muchos números en una estadística. Por ejemplo, **media**, **mediana**, **mínimo**, **máximo** y **desviación estándar** son estadísticas de resumen. Calcular estadísticas de resumen te permite conocer mejor tus datos, incluso si hay muchos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprime el encabezado del DataFrame sales\n",
    "print(sales.head())\n",
    "\n",
    "# Imprime la información sobre el DataFrame sales\n",
    "print(sales.info())\n",
    "\n",
    "# Imprime la media de weekly_sales\n",
    "print(sales[\"weekly_sales\"].mean())\n",
    "\n",
    "# Imprime la mediana de weekly_sales\n",
    "print(sales[\"weekly_sales\"].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "   store type  department       date  weekly_sales  is_holiday  temperature_c  fuel_price_usd_per_l  unemployment\n",
    "0      1    A           1 2010-02-05      24924.50       False          5.728                 0.679         8.106\n",
    "1      1    A           1 2010-03-05      21827.90       False          8.056                 0.693         8.106\n",
    "2      1    A           1 2010-04-02      57258.43       False         16.817                 0.718         7.808\n",
    "3      1    A           1 2010-05-07      17413.94       False         22.528                 0.749         7.808\n",
    "4      1    A           1 2010-06-04      17558.09       False         27.050                 0.715         7.808\n",
    "\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "RangeIndex: 10774 entries, 0 to 10773\n",
    "Data columns (total 9 columns):\n",
    " #   Column                Non-Null Count  Dtype         \n",
    "---  ------                --------------  -----         \n",
    " 0   store                 10774 non-null  int64         \n",
    " 1   type                  10774 non-null  object        \n",
    " 2   department            10774 non-null  int32         \n",
    " 3   date                  10774 non-null  datetime64[ns]\n",
    " 4   weekly_sales          10774 non-null  float64       \n",
    " 5   is_holiday            10774 non-null  bool          \n",
    " 6   temperature_c         10774 non-null  float64       \n",
    " 7   fuel_price_usd_per_l  10774 non-null  float64       \n",
    " 8   unemployment          10774 non-null  float64       \n",
    "dtypes: bool(1), datetime64[ns](1), float64(4), int32(1), int64(1), object(1)\n",
    "memory usage: 641.9+ KB\n",
    "None\n",
    "\n",
    "23843.95014850566\n",
    "\n",
    "12049.064999999999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumiendo fechas\n",
    "Las estadísticas de resumen también se pueden calcular en columnas de fechas que tienen valores con el tipo de datos ```datetime64```. Algunas estadísticas de resumen, como la media, no tienen mucho sentido en las fechas, pero otras son súper útiles, por ejemplo, mínimo y máximo, que te permiten ver qué rango de tiempo cubren tus datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprime el máximo de la columna date\n",
    "print(sales[\"date\"].max())\n",
    "\n",
    "# Imprime el mínimo de la columna date\n",
    "print(sales[\"date\"].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "2012-10-26 00:00:00\n",
    "2010-02-05 00:00:00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resúmenes eficientes\n",
    "Si bien ```pandas``` y ```NumPy``` tienen toneladas de funciones, a veces, es posible que necesites una función diferente para resumir tus datos.\n",
    "\n",
    "El método ```.agg()``` te permite aplicar tus propias funciones personalizadas a un ```DataFrame```, así como aplicar funciones a más de una columna de un ```DataFrame``` a la vez, haciendo que tus agregaciones sean super eficientes. Por ejemplo,\n",
    "```python\n",
    "df['column'].agg(function)\n",
    "```\n",
    "En la función personalizada para este ejercicio, ```\"IQR\"``` es la abreviatura de rango inter-cuartil, que es el percentil 75 menos el percentil 25. Es una alternativa a la desviación estándar que es útil si los datos contienen valores atípicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Una función IQR personalizada\n",
    "def iqr(column):\n",
    "    return column.quantile(0.75) - column.quantile(0.25)\n",
    "    \n",
    "# Imprime IQR de la columna temperature_c\n",
    "print(sales[\"temperature_c\"].agg(iqr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "16.583333333333336"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Una función IQR personalizada\n",
    "def iqr(column):\n",
    "    return column.quantile(0.75) - column.quantile(0.25)\n",
    "\n",
    "# Actualiza el código para imprimir IQR de temperature_c, fuel_price_usd_per_l y unemployment\n",
    "print(sales[[\"temperature_c\", \"fuel_price_usd_per_l\", \"unemployment\"]].agg(iqr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "temperature_c           16.583\n",
    "fuel_price_usd_per_l     0.073\n",
    "unemployment             0.565\n",
    "dtype: float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa NumPy y crea una función IQR personalizada\n",
    "import numpy as np\n",
    "def iqr(column):\n",
    "    return column.quantile(0.75) - column.quantile(0.25)\n",
    "\n",
    "# Actualiza el código para imprimir IQR y np.median de temperature_c, fuel_price_usd_per_l, y unemployment\n",
    "print(sales[[\"temperature_c\", \"fuel_price_usd_per_l\", \"unemployment\"]].agg([iqr, np.median]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "        temperature_c  fuel_price_usd_per_l  unemployment\n",
    "iqr            16.583                 0.073         0.565\n",
    "median         16.967                 0.743         8.099"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estadísticas acumuladas\n",
    "Las estadísticas acumuladas también pueden ser útiles para dar seguimiento de las estadísticas de resumen a lo largo del tiempo. En este ejercicio, calcularás la suma acumulada y el máximo acumulativo de las ventas semanales de un departamento, lo que te permitirá identificar cuáles fueron las ventas totales hasta ahora, así como cuáles fueron las ventas semanales más altas hasta ahora.\n",
    "\n",
    "Se ha creado para ti un DataFrame llamado ```sales_1_1```, que contiene los datos de ventas del departamento 1 de la tienda 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordena sales_1_1 por date\n",
    "sales_1_1 = sales_1_1.sort_values(\"date\")\n",
    "\n",
    "# Obtén la suma acumulada de weekly_sales, y añádela como cum_weekly_sales\n",
    "sales_1_1[\"cum_weekly_sales\"] = sales_1_1[\"weekly_sales\"].cumsum()\n",
    "\n",
    "# Obtén el máximo acumulativo de weekly_sales y añádelo como cum_max_sales\n",
    "sales_1_1[\"cum_max_sales\"] = sales_1_1[\"weekly_sales\"].cummax()\n",
    "\n",
    "# Consulta las columnas que calculaste\n",
    "print(sales_1_1[[\"date\", \"weekly_sales\", \"cum_weekly_sales\", \"cum_max_sales\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "         date  weekly_sales  cum_weekly_sales  cum_max_sales\n",
    "0  2010-02-05      24924.50          24924.50       24924.50\n",
    "1  2010-03-05      21827.90          46752.40       24924.50\n",
    "2  2010-04-02      57258.43         104010.83       57258.43\n",
    "3  2010-05-07      17413.94         121424.77       57258.43\n",
    "4  2010-06-04      17558.09         138982.86       57258.43\n",
    "5  2010-07-02      16333.14         155316.00       57258.43\n",
    "6  2010-08-06      17508.41         172824.41       57258.43\n",
    "7  2010-09-03      16241.78         189066.19       57258.43\n",
    "8  2010-10-01      20094.19         209160.38       57258.43\n",
    "9  2010-11-05      34238.88         243399.26       57258.43\n",
    "10 2010-12-03      22517.56         265916.82       57258.43\n",
    "11 2011-01-07      15984.24         281901.06       57258.43"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminando duplicados\n",
    "Eliminar duplicados es una habilidad esencial para obtener recuentos precisos porque, a menudo, no quieres contar lo mismo varias veces. En este ejercicio, crearás algunos DataFrames nuevos utilizando valores únicos de sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elimina combinaciones duplicadas de store/type\n",
    "store_types = sales.drop_duplicates(subset=[\"store\", \"type\"])\n",
    "print(store_types.head())\n",
    "\n",
    "# Elimina combinaciones duplicadas de store/department\n",
    "store_depts = sales.drop_duplicates(subset=[\"store\", \"department\"])\n",
    "print(store_depts.head())\n",
    "\n",
    "# Selecciona las filas donde is_holiday es True y elimina fechas duplicadas\n",
    "holiday_dates = sales[sales[\"is_holiday\"] == True].drop_duplicates(subset=\"date\")\n",
    "\n",
    "# Imprime la columna date de holiday_dates\n",
    "print(holiday_dates[\"date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "      store type  department       date  weekly_sales  is_holiday  temperature_c  fuel_price_usd_per_l  unemployment\n",
    "0         1    A           1 2010-02-05      24924.50       False          5.728                 0.679         8.106\n",
    "901       2    A           1 2010-02-05      35034.06       False          4.550                 0.679         8.324\n",
    "1798      4    A           1 2010-02-05      38724.42       False          6.533                 0.686         8.623\n",
    "2699      6    A           1 2010-02-05      25619.00       False          4.683                 0.679         7.259\n",
    "3593     10    B           1 2010-02-05      40212.84       False         12.411                 0.782         9.765\n",
    "\n",
    "    store type  department       date  weekly_sales  is_holiday  temperature_c  fuel_price_usd_per_l  unemployment\n",
    "0       1    A           1 2010-02-05      24924.50       False          5.728                 0.679         8.106\n",
    "12      1    A           2 2010-02-05      50605.27       False          5.728                 0.679         8.106\n",
    "24      1    A           3 2010-02-05      13740.12       False          5.728                 0.679         8.106\n",
    "36      1    A           4 2010-02-05      39954.04       False          5.728                 0.679         8.106\n",
    "48      1    A           5 2010-02-05      32229.38       False          5.728                 0.679         8.106\n",
    "\n",
    "498    2010-09-10\n",
    "691    2011-11-25\n",
    "2315   2010-02-12\n",
    "6735   2012-09-07\n",
    "6810   2010-12-31\n",
    "6815   2012-02-10\n",
    "6820   2011-09-09"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contando variables categóricas\n",
    "Contar es una excelente manera de obtener una visión general de tus datos y detectar curiosidades que de otra manera no notarías. En este ejercicio, contarás el número de cada tipo de tienda y el número de cada departamento utilizando los DataFrames que creaste en el ejercicio anterior:\n",
    "```python\n",
    "# Elimina combinaciones duplicadas de store/type\n",
    "store_types = sales.drop_duplicates(subset=[\"store\", \"type\"])\n",
    "\n",
    "# Elimina combinaciones duplicadas de store/department\n",
    "store_depts = sales.drop_duplicates(subset=[\"store\", \"department\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cuenta el número de tiendas de cada type\n",
    "store_counts = store_types[\"type\"].value_counts()\n",
    "print(store_counts)\n",
    "\n",
    "# Obtén la proporción de tiendas de cada type\n",
    "store_props = store_types[\"type\"].value_counts(normalize=True)\n",
    "print(store_props)\n",
    "\n",
    "# Cuenta el número de cada department y ordena\n",
    "dept_counts_sorted = store_depts[\"department\"].value_counts(sort=True)\n",
    "print(dept_counts_sorted)\n",
    "\n",
    "# Obtén la proporción de cada department y ordena\n",
    "dept_props_sorted = store_depts[\"department\"].value_counts(sort=True, normalize=True)\n",
    "print(dept_props_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "A    11\n",
    "B     1\n",
    "Name: type, dtype: int64\n",
    "\n",
    "A    0.917\n",
    "B    0.083\n",
    "Name: type, dtype: float64\n",
    "\n",
    "1     12\n",
    "55    12\n",
    "72    12\n",
    "71    12\n",
    "67    12\n",
    "      ..\n",
    "37    10\n",
    "48     8\n",
    "50     6\n",
    "39     4\n",
    "43     2\n",
    "Name: department, Length: 80, dtype: int64\n",
    "\n",
    "1     0.013\n",
    "55    0.013\n",
    "72    0.013\n",
    "71    0.013\n",
    "67    0.013\n",
    "      ...  \n",
    "37    0.011\n",
    "48    0.009\n",
    "50    0.006\n",
    "39    0.004\n",
    "43    0.002\n",
    "Name: department, Length: 80, dtype: float64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Qué porcentaje de las ventas ocurrió en cada tipo de tienda?\n",
    "Aunque ```.groupby()``` es útil, puedes calcular estadísticas de resumen agrupadas sin él.\n",
    "\n",
    "Walmart distingue tres tipos de tiendas: ```\"supercenters\"```, ```\"discount stores,\"``` y ```\"neighborhood markets\"```, codificados en este conjunto de datos como tipo ```\"A\"```, ```\"B\"``` y ```\"C\"```. En este ejercicio, calcularás las ventas totales de cada tipo de tienda, sin usar ```.groupby()```. Después, podremos utilizar estos números para ver qué proporción de las ventas totales de Walmart se realizaron en cada tipo de tienda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Selecciona las tiendas tipo A, calcula las ventas semanales totales\n",
    "sales_A = sales[sales[\"type\"] == \"A\"][\"weekly_sales\"].sum()\n",
    "\n",
    "# Selecciona las tiendas tipo B, calcula las ventas semanales totales\n",
    "sales_B = sales[sales[\"type\"] == \"B\"][\"weekly_sales\"].sum()\n",
    "\n",
    "# Selecciona las tiendas tipo C, calcula las ventas semanales totales\n",
    "sales_C = sales[sales[\"type\"] == \"C\"][\"weekly_sales\"].sum()\n",
    "\n",
    "# Obtén la proporción de cada tipo\n",
    "sales_propn_by_type = [sales_A, sales_B, sales_C] / sales_all\n",
    "print(sales_propn_by_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "[0.9097747 0.0902253       nan]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cálculos con ```.groupby()```\n",
    "El método ```.groupby()``` hace la vida mucho más fácil. En este ejercicio, realizarás los mismos cálculos de la última vez, excepto que usarás el método ```.groupby()```. También realizarás cálculos en datos agrupados por dos variables para ver si las ventas difieren según el tipo de tienda dependiendo de si es una semana de vacaciones o no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupa por type; calcula la suma de weekly_sales\n",
    "sales_by_type = sales.groupby(\"type\")[\"weekly_sales\"].sum()\n",
    "\n",
    "# Obtén la proporción de cada tipo\n",
    "sales_propn_by_type =  sales_by_type/ sum(sales_by_type)\n",
    "print(sales_propn_by_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "type\n",
    "A    0.91\n",
    "B    0.09\n",
    "Name: weekly_sales, dtype: float64\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Del paso anterior\n",
    "sales_by_type = sales.groupby(\"type\")[\"weekly_sales\"].sum()\n",
    "\n",
    "# Agrupa por type y por is_holiday; calcula el total de weekly_sales\n",
    "sales_by_type_is_holiday = sales.groupby([\"type\", \"is_holiday\"])[\"weekly_sales\"].sum()\n",
    "print(sales_by_type_is_holiday)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "type  is_holiday\n",
    "A     False         2.337e+08\n",
    "      True          2.360e+04\n",
    "B     False         2.318e+07\n",
    "      True          1.621e+03\n",
    "Name: weekly_sales, dtype: float64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resúmenes agrupados múltiples\n",
    "Anteriormente en este capítulo, viste que el método ```.agg()``` es útil para calcular múltiples estadísticas sobre múltiples variables. También funciona con datos agrupados. ```NumPy```, que se importa como ```np```, tiene muchas funciones estadísticas de resumen diferentes, incluyendo: ```np.min```, ```np.max```, ```np.mean``` y ```np.median```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa numpy con el alias np\n",
    "import numpy as np\n",
    "\n",
    "# Para cada tipo de tienda, agrega weekly_sales: obtén min, max, media y mediana\n",
    "sales_stats = sales.groupby(\"type\")[\"weekly_sales\"].agg([np.min, np.max, np.mean, np.median])\n",
    "\n",
    "# Imprime sales_stats\n",
    "print(sales_stats, \"\\n\")\n",
    "\n",
    "# Para cada tipo de tienda, agrega unemployment y fuel_price_usd_per_l: obtén mínimo, máximo, media y mediana\n",
    "unemp_fuel_stats = sales.groupby(\"type\")[\"unemployment\", \"fuel_price_usd_per_l\"].agg([np.min, np.max, np.mean, np.median])\n",
    "\n",
    "# Imprime unemp_fuel_stats\n",
    "print(unemp_fuel_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "        amin       amax       mean    median\n",
    "type                                        \n",
    "A    -1098.0  293966.05  23674.667  11943.92\n",
    "B     -798.0  232558.51  25696.678  13336.08 \n",
    "\n",
    "                  unemployment                           fuel_price_usd_per_l                     \n",
    "             amin   amax   mean median                 amin   amax   mean median\n",
    "type                                                                            \n",
    "A           3.879  8.992  7.973  8.067                0.664  1.107  0.745  0.735\n",
    "B           7.170  9.765  9.279  9.199                0.760  1.108  0.806  0.803"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pivot en una variable\n",
    "Las tablas dinámicas (pivot tables) son la forma estándar de agregar datos en hojas de cálculo.\n",
    "\n",
    "En pandas, las tablas dinámicas son esencialmente otra forma de realizar cálculos agrupados. Es decir, el método ```.pivot_table()``` es una alternativa a ```.groupby()```.\n",
    "\n",
    "En este ejercicio, realizarás cálculos usando ```.pivot_table()``` para replicar los cálculos que realizamos en la última lección usando .```groupby()```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usa pivot_table para calcular la media de weekly_sales por tipo de tienda\n",
    "mean_sales_by_type = sales.pivot_table(values = \"weekly_sales\", index = \"type\")\n",
    "\n",
    "# Imprime mean_sales_by_type\n",
    "print(mean_sales_by_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "      weekly_sales\n",
    "type              \n",
    "A        23674.667\n",
    "B        25696.678"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa NumPy as np\n",
    "import numpy as np\n",
    "\n",
    "# Usa pivot_table para calcular la medias y mediana de weekly_sales para cada tipo de tienda\n",
    "mean_med_sales_by_type = sales.pivot_table(values = \"weekly_sales\", index = \"type\", aggfunc = [np.mean, np.median])\n",
    "\n",
    "# Imprime mean_med_sales_by_type\n",
    "print(mean_med_sales_by_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "             mean       median\n",
    "     weekly_sales weekly_sales\n",
    "type                          \n",
    "A       23674.667     11943.92\n",
    "B       25696.678     13336.08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usa pivot_table para calcular la media de weekly_sales por type y por is_holiday \n",
    "mean_sales_by_type_holiday = sales.pivot_table(values = \"weekly_sales\", index = [\"type\", \"is_holiday\"])\n",
    "\n",
    "# Imprime mean_sales_by_type_holiday\n",
    "print(mean_sales_by_type_holiday)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "is_holiday      False     True\n",
    "type                          \n",
    "A           23768.584  590.045\n",
    "B           25751.981  810.705"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rellenando valores faltantes y sumando valores con tablas dinámicas\n",
    "El método ```.pivot_table()``` tiene varios argumentos útiles, incluyendo ```fill_value``` y ```margins```.\n",
    "\n",
    "```fill_value``` reemplaza los valores faltantes por un valor real (conocido como imputación). Con qué reemplazar los valores faltantes es un tema lo suficientemente grande como para tener su propio curso (Lidiando con datos faltantes en Python), pero lo más simple es sustituir por un valor ficticio.\n",
    "\n",
    "```margins``` es un atajo para cuando agrupamos con dos variables, pero también queríamos agrupar por cada una de esas variables independientemente: nos da los totales de fila y columna de la tabla dinámica.\n",
    "\n",
    "En este ejercicio, practicarás el uso de estos argumentos para mejorar tus habilidades con ```pivot_table```, ¡lo que te ayudará a hacer cálculos de manera más eficiente!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprime la media de weekly_sales por department y type; rellena valores faltantes con 0\n",
    "print(sales.pivot_table(values = \"weekly_sales\", index = \"type\", columns = \"department\", fill_value = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "department      1           2          3          4          5   ...          95         96         97         98       99\n",
    "type                                                                ...                                                      \n",
    "A        30961.725   67600.159  17160.003  44285.399  34821.011  ...  123933.787  21367.043  28471.267  12875.423  379.124\n",
    "B        44050.627  112958.527  30580.655  51219.654  63236.875  ...   77082.102   9528.538   5828.873    217.428    0.000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprime la media de weekly_sales por department y type; rellena los valores faltantes con 0s; suma todas las filas y columnas\n",
    "print(sales.pivot_table(values=\"weekly_sales\", index=\"type\", columns=\"department\", margins = True, fill_value = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "department          1           2          3          4          5  ...         96         97         98       99        All\n",
    "type                                                                ...                                                     \n",
    "A           30961.725   67600.159  17160.003  44285.399  34821.011  ...  21367.043  28471.267  12875.423  379.124  23674.667\n",
    "B           44050.627  112958.527  30580.655  51219.654  63236.875  ...   9528.538   5828.873    217.428    0.000  25696.678\n",
    "All         32052.467   71380.023  18278.391  44863.254  37189.000  ...  20337.608  26584.401  11820.590  379.124  23843.950"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
